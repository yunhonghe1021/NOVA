<html class="fontawesome-i2svg-active fontawesome-i2svg-complete"><head>
    <meta charset="utf-8">
    <meta name="description"
          content="Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis.">
    <meta name="keywords" content="Real3D-Portrait, One-shot, NeRF">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Rebuttal Demos for Real3D-Portrait </title>
  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
  
      function gtag() {
        dataLayer.push(arguments);
      }
  
      gtag('js', new Date());
  
      gtag('config', 'G-PYVRSFMDRL');
    </script>
  
    <style type="text/css">svg:not(:root).svg-inline--fa{overflow:visible}.svg-inline--fa{display:inline-block;font-size:inherit;height:1em;overflow:visible;vertical-align:-.125em}.svg-inline--fa.fa-lg{vertical-align:-.225em}.svg-inline--fa.fa-w-1{width:.0625em}.svg-inline--fa.fa-w-2{width:.125em}.svg-inline--fa.fa-w-3{width:.1875em}.svg-inline--fa.fa-w-4{width:.25em}.svg-inline--fa.fa-w-5{width:.3125em}.svg-inline--fa.fa-w-6{width:.375em}.svg-inline--fa.fa-w-7{width:.4375em}.svg-inline--fa.fa-w-8{width:.5em}.svg-inline--fa.fa-w-9{width:.5625em}.svg-inline--fa.fa-w-10{width:.625em}.svg-inline--fa.fa-w-11{width:.6875em}.svg-inline--fa.fa-w-12{width:.75em}.svg-inline--fa.fa-w-13{width:.8125em}.svg-inline--fa.fa-w-14{width:.875em}.svg-inline--fa.fa-w-15{width:.9375em}.svg-inline--fa.fa-w-16{width:1em}.svg-inline--fa.fa-w-17{width:1.0625em}.svg-inline--fa.fa-w-18{width:1.125em}.svg-inline--fa.fa-w-19{width:1.1875em}.svg-inline--fa.fa-w-20{width:1.25em}.svg-inline--fa.fa-pull-left{margin-right:.3em;width:auto}.svg-inline--fa.fa-pull-right{margin-left:.3em;width:auto}.svg-inline--fa.fa-border{height:1.5em}.svg-inline--fa.fa-li{width:2em}.svg-inline--fa.fa-fw{width:1.25em}.fa-layers svg.svg-inline--fa{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.fa-layers{display:inline-block;height:1em;position:relative;text-align:center;vertical-align:-.125em;width:1em}.fa-layers svg.svg-inline--fa{-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter,.fa-layers-text{display:inline-block;position:absolute;text-align:center}.fa-layers-text{left:50%;top:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter{background-color:#ff253a;border-radius:1em;-webkit-box-sizing:border-box;box-sizing:border-box;color:#fff;height:1.5em;line-height:1;max-width:5em;min-width:1.5em;overflow:hidden;padding:.25em;right:0;text-overflow:ellipsis;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-bottom-right{bottom:0;right:0;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom right;transform-origin:bottom right}.fa-layers-bottom-left{bottom:0;left:0;right:auto;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom left;transform-origin:bottom left}.fa-layers-top-right{right:0;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-top-left{left:0;right:auto;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top left;transform-origin:top left}.fa-lg{font-size:1.3333333333em;line-height:.75em;vertical-align:-.0667em}.fa-xs{font-size:.75em}.fa-sm{font-size:.875em}.fa-1x{font-size:1em}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-6x{font-size:6em}.fa-7x{font-size:7em}.fa-8x{font-size:8em}.fa-9x{font-size:9em}.fa-10x{font-size:10em}.fa-fw{text-align:center;width:1.25em}.fa-ul{list-style-type:none;margin-left:2.5em;padding-left:0}.fa-ul>li{position:relative}.fa-li{left:-2em;position:absolute;text-align:center;width:2em;line-height:inherit}.fa-border{border:solid .08em #eee;border-radius:.1em;padding:.2em .25em .15em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left,.fab.fa-pull-left,.fal.fa-pull-left,.far.fa-pull-left,.fas.fa-pull-left{margin-right:.3em}.fa.fa-pull-right,.fab.fa-pull-right,.fal.fa-pull-right,.far.fa-pull-right,.fas.fa-pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.fa-rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-webkit-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{-webkit-transform:scale(1,-1);transform:scale(1,-1)}.fa-flip-both,.fa-flip-horizontal.fa-flip-vertical{-webkit-transform:scale(-1,-1);transform:scale(-1,-1)}:root .fa-flip-both,:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{-webkit-filter:none;filter:none}.fa-stack{display:inline-block;height:2em;position:relative;width:2.5em}.fa-stack-1x,.fa-stack-2x{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.svg-inline--fa.fa-stack-1x{height:1em;width:1.25em}.svg-inline--fa.fa-stack-2x{height:2em;width:2.5em}.fa-inverse{color:#fff}.sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.sr-only-focusable:active,.sr-only-focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}.svg-inline--fa .fa-primary{fill:var(--fa-primary-color,currentColor);opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa .fa-secondary{fill:var(--fa-secondary-color,currentColor);opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-primary{opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-secondary{opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa mask .fa-primary,.svg-inline--fa mask .fa-secondary{fill:#000}.fad.fa-inverse{color:#fff}</style><link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
    <link rel="stylesheet" href="../css/bulma.min.css">
    <link rel="stylesheet" href="../css/bulma-carousel.min.css">
    <link rel="stylesheet" href="../css/bulma-slider.min.css">
    <link rel="stylesheet" href="../css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="../css/index.css">
    <link rel="icon" href="../images/3dface_logo.png">
  
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer="" src="../js/fontawesome.all.min.js"></script>
    <script src="../js/bulma-carousel.min.js"></script>
    <script src="../js/bulma-slider.min.js"></script>
    <script src="../js/index.js"></script>
  </head>
  <body>
  
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Rebuttal Demos for Real3D-Portrait</h1>
  
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="../../index.html" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>HomePage</span>
                  </a>
                </span>
              </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <section class="section">
    <div class="container is-max-desktop">
  
      <!-- Demo Main -->
      <h1 class="title is-3">Rebuttal Demo 1: Motion Adapter versus Deformation Field</h1>
        <div class="content has-text-justified">
        <p>
            To better demonatrate the superiority of motion adapter to morph the 3D face, we provide a demo that visualizes the depth and color image of the deform-based model (replace the motion adapter with HiDe-NeRF's deformation field) and our motion adapter-based model when driven by an audio.
        </p>
        </div>
        <div class="content has-text-centered">
        <video id="replay-video"
                controls
                preload
                playsinline
                width="60%">
            <source src="../videos/Comparison_with_deformation.mp4"
                    type="video/mp4">
        </video>
      </div>
      <!--/ Demo Main -->

            <!-- Demo Main -->
            <h1 class="title is-3">Rebuttal Demo 2: I2P model performing Multi-View Synthesis</h1>
            <div class="content has-text-justified">
            <p>
                To better demonatrate that our image-to-plane (I2P) model could reconstruct the 3D face mesh given the source image, we extract the I2P model form the Real3D-Portrait's final checkpoint, and directly volume renders the canonical tri-planes produced by the I2P model.
            </p>
            </div>
            <div class="content has-text-centered">
            <video id="replay-video"
                    controls
                    preload
                    playsinline
                    width="50%">
                <source src="../videos/I2P_multi_view_synthesis.mp4"
                        type="video/mp4">
            </video>
          </div>
          <!--/ Demo Main -->

            <!-- Demo Main -->
            <h1 class="title is-3">Rebuttal Demo 3: Comparison with Next3D+PTI</h1>
            <div class="content has-text-justified">
            <p>
                We additionally compare with Next3D+PTI, Next3D is a 3D Face GAN that improves the EG3D with better controllability. PTI is a popular GAN inversion technique.
            </p>
            </div>
            <div class="content has-text-centered">
            <video id="replay-video"
                    controls
                    preload
                    playsinline
                    width="75%">
                <source src="../videos/Comparison_with_Next3D.mp4",
                        type="video/mp4">
            </video>
          </div>
          <!--/ Demo Main -->


            <!-- Demo Main -->
            <h1 class="title is-3">Rebuttal Demo 4: Real3D-Portrait generalizes well with Diffcult Source Images</h1>
            <div class="content has-text-justified">
            <p>
                  In the following video, we should that our image-to-plane model and motion adapter could well handles source image with arbitrary expression. For instance, large-opened mouth, lowered jay, and closed eyes.
            </p>
            </div>
            <div class="content has-text-centered">
            <video id="replay-video"
                    controls
                    preload
                    playsinline
                    width="75%">
                <source src="../videos/Demo_critical_source_images.mp4"
                        type="video/mp4">
            </video>
            </div>
            <!--/ Demo Main -->

            <!-- Demo Main -->
            <h1 class="title is-3">Rebuttal Demo 5: Comparison with 5 Video-driven 2D methods</h1>
            <div class="content has-text-justified">
            <p>
                In the following video, we show that our method achieves better performance than 5 additional 2D baselines at a large head pose.
            </p>
            </div>
            <div class="content has-text-centered">
            <video id="replay-video"
                    controls
                    preload
                    playsinline
                    width="75%">
                <source src="../videos/Comparison_with_5_additional_VD_baselines.mp4"
                        type="video/mp4">
            </video>
            </div>
            <!--/ Demo Main -->

            <!-- Demo Main -->
            <h1 class="title is-3">Rebuttal Demo 6: Comparison with AUD</h1>
            <div class="content has-text-justified">
            <p>
                AUD (Audio-driven talking face video generation with learning-based personalized head pose. arXiv:2002.10137.) is a person-specific audio-driven method, we use a 2-minute-long video to train a Obama model.
            </p>
            </div>
            <div class="content has-text-centered">
            <video id="replay-video"
                    controls
                    preload
                    playsinline
                    width="75%">
                <source src="../videos/Comparison_with_AUD.mp4"
                        type="video/mp4">
            </video>
            </div>
            <!--/ Demo Main -->

            <!-- Demo Main -->
            <h1 class="title is-3">Rebuttal Demo 7: Comparison with DFA-NeRF</h1>
            <div class="content has-text-justified">
            <p>
                  DFA-NeRF (arXiv:2002.10137) is a person-specific audio-driven method, we use a 2-minute-long video to train a Obama model. Since the DFA-NeRF official repo is incomplete, the current supported setting to obtain a reasonable result of DFA-NeRF is driving the model with a fixed pose and GT expression sequence.
            </p>
            </div>
            <div class="content has-text-centered">
            <video id="replay-video"
                    controls
                    preload
                    playsinline
                    width="75%">
                  <source src="../videos/Comparison_with_DFANeRF.mp4",
                        type="video/mp4">
            </video>
            </div>
            <!--/ Demo Main -->


      <!-- Demo Main -->
      <h1 class="title is-3">Post-Rebuttal Demo 1: Mesh Visualization between Real3D-Portrait and Deformation Field</h1>
      <div class="content has-text-justified">
        <p>
          To better compare the predicted geometry (both depth and surface normals), we follow the instructions from EG3D <a href="https://github.com/NVlabs/eg3d#generating-media">in this link </a>. 
          We can see that our method with I2P model and motion adapter could reconstruct good geometry while the deformation field
        </p>
      </div>
      <div class="content has-text-centered">
        <video id="replay-video"
              controls
              preload
              playsinline
              width="90%">
          <source src="../videos/Visualiztion_MRC_Mesh.mp4"
                  type="video/mp4">
        </video>
      </div>
    <!-- Demo Main -->

    <!-- Demo Main -->
    <h1 class="title is-3">Post-Rebuttal Demo 2: Lowered yaw expression source image</h1>
    <div class="content has-text-justified">
        <p>
            In the following demo, we show that our I2P model and Motion Adapter generalize well to hard source images with a lowered yaw expression.
        </p>
        </div>
        <div class="content has-text-centered">
        <video id="replay-video"
                controls
                preload
                playsinline
                width="90%">
            <source src="../videos/Demo_lowered_yaw_expression.mp4"
                    type="video/mp4">
        </video>
    </div>

    <!-- Demo Main -->

    </div>
  </section>
  
              
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{ye2024real3dportrait,
    author    = {Ye, Zhenhui and Zhong, Tianyun and Ren, Yi and Yang, Jiaqi and Li, Weichuang and Huang, Jiangwei and Jiang, Ziyue and He, Jinzheng and Huang, Rongjie and Liu, Jinglin and Zhang, Chen and Yin, Xiang and Ma, Zejun and Zhao, Zhou},
    title     = {Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis},
    journal   = {ICLR},
    year      = {2024},
  }</code></pre>
    </div>
  </section>
  
  
  
  
</body></html>

  